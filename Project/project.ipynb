{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, score = None):\n",
    "        self.score = score\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.feature = None\n",
    "        self.split = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "reference:https://towardsdatascience.com/all-you-need-to-know-about-gradient-boosting-algorithm-part-2-classification-d3ed8f56541e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticloss(y,y_pred):\n",
    "    l = np.log(1+np.exp(-2*y*y_pred))\n",
    "    return l\n",
    "\n",
    "def logisticloss_gradient(y,y_pred):\n",
    "    ri = 2*y/(1 + np.exp(2*y*y_pred))\n",
    "\n",
    "    return ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gradient_boosting(object):\n",
    "    def __init__(self,M,base_model=\"CART\",max_depth = 1,learning_rate = 1, method = \"binary classification\",loss = \"logistic\",tol = None):\n",
    "        self.M = M\n",
    "        self.base_model = base_model\n",
    "        self.max_depth = max_depth\n",
    "        self.learning_rate = learning_rate\n",
    "        self.method = method\n",
    "        self.loss = loss\n",
    "        self.tol = tol\n",
    "        self.trees = []\n",
    "        self.num_class = None\n",
    "        self.col_names = None\n",
    "\n",
    "    def fit(self,x,y):\n",
    "\n",
    "        one_hot = None\n",
    "\n",
    "        # binary classification#############################################################################################\n",
    "\n",
    "        # initial prediction\n",
    "        if self.method == \"binary classification\":\n",
    "\n",
    "            self.num_class = 2\n",
    "\n",
    "            F0 = np.log(np.mean(y)/(1-np.mean(y)))\n",
    "            self.F0 = np.array([F0]*len(y))\n",
    "\n",
    "            # mth tree's predict value\n",
    "            fm = self.F0.copy()\n",
    "        \n",
    "\n",
    "        # multiclass classification#########################################################################################\n",
    "\n",
    "        \n",
    "\n",
    "        if self.method == \"multiclass classification\":\n",
    "            # count number of classes \n",
    "            num_classes = y.nunique()\n",
    "            self.num_class = num_classes\n",
    "\n",
    "            # one-hot encoding\n",
    "            one_hot = pd.get_dummies(y)\n",
    "\n",
    "            # get column names\n",
    "            self.col_names = one_hot.columns.tolist()\n",
    "            \n",
    "            # initial prediction\n",
    "            F0 = []\n",
    "\n",
    "            for i in range(num_classes):\n",
    "                coli = one_hot.iloc[:,i]\n",
    "                num_class_i = coli.value_counts()[1]\n",
    "                F0.append(np.array([num_class_i/len(y)]*len(y)))\n",
    "            \n",
    "            \n",
    "            self.F0 = F0\n",
    "\n",
    "            fm = self.F0.copy()\n",
    "\n",
    "        # binary classification######################################################################################################\n",
    "\n",
    "        if self.method == \"binary classification\":\n",
    "\n",
    "            for m in range(self.M):\n",
    "                \n",
    "                \n",
    "                # compute residual\n",
    "                p = np.exp(fm)/(1 + np.exp(fm))\n",
    "                r_im = y - p\n",
    "\n",
    "                if self.base_model == \"CART\":\n",
    "                    #fit a regression tree using residual\n",
    "                    tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "                    tree.fit(x, r_im)\n",
    "                    nodes = tree.apply(x)\n",
    "\n",
    "                    for i in np.unique(nodes):\n",
    "\n",
    "                        # find subset of data points belong to node i\n",
    "                        sub = i == nodes\n",
    "\n",
    "                        #compute the leaf value for node i\n",
    "                        gamma = (np.sum(r_im[sub]))/(np.sum(p[sub]*(1-p[sub])))\n",
    "\n",
    "                        # update predict value for all data points belong to node i\n",
    "                        fm[sub] += self.learning_rate*gamma\n",
    "\n",
    "                        # update leaf value\n",
    "                        tree.tree_.value[i, 0, 0] = gamma\n",
    "                \n",
    "                    self.trees.append(tree)\n",
    "            \n",
    "        # multiclass classification############################################################################################################\n",
    "\n",
    "        if self.method == \"multiclass classification\":\n",
    "\n",
    "            for m in range(self.M):\n",
    "                K = y.nunique()\n",
    "\n",
    "                if self.base_model == \"CART\":\n",
    "                    # compute p\n",
    "                    p = []\n",
    "                    ktrees = []\n",
    "\n",
    "                    # compute denominator\n",
    "\n",
    "                    den = np.array([0]*len(y)).astype(np.float64)\n",
    "                    for l in range(K):\n",
    "                        den += np.exp(fm[l])\n",
    "\n",
    "\n",
    "                    for k in range(K):\n",
    "\n",
    "                        # kth tree\n",
    "                        p_km = np.exp(fm[k]) / den\n",
    "                        p.append(p_km)\n",
    "\n",
    "                        # compute residual for all y\n",
    "                        r_km = one_hot[k] - p_km\n",
    "\n",
    "                    \n",
    "\n",
    "                        # fit kth CART tree\n",
    "                        tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "                        tree.fit(x, r_km)\n",
    "                        nodes = tree.apply(x)\n",
    "\n",
    "                        for i in np.unique(nodes):\n",
    "\n",
    "                            # find subset of data points belong to node i\n",
    "                            sub = i == nodes\n",
    "\n",
    "                            #compute the leaf value for node i\n",
    "                            gamma = ((K-1)/K) * (np.sum(np.abs(r_km[sub]))/(np.sum(np.abs(r_km[sub])*(1-np.abs(r_km[sub])))))\n",
    "\n",
    "                            # update predict value for all data points belong to node i\n",
    "                            fm[k][sub] += self.learning_rate*gamma\n",
    "\n",
    "                            # update leaf value\n",
    "                            tree.tree_.value[i, 0, 0] = gamma\n",
    "                \n",
    "                        ktrees.append(tree)\n",
    "\n",
    "                    self.trees.append(ktrees)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "    def predit(self,x):\n",
    "        if self.method == \"binary classification\":\n",
    "            Fm = self.F0\n",
    "\n",
    "            for m in range(self.M):\n",
    "                Fm += self.learning_rate * self.trees[m].predict(x)\n",
    "\n",
    "            prob = np.exp(Fm)/(1 + np.exp(Fm))\n",
    "            \n",
    "            return prob\n",
    "\n",
    "\n",
    "        if self.method == \"multiclass classification\":\n",
    "            Fm = self.F0\n",
    "\n",
    "            # create probability dataframe\n",
    "            prob = pd.DataFrame(columns=self.col_names)\n",
    "\n",
    "            for m in range(self.M):\n",
    "                for k in range(self.num_class):\n",
    "\n",
    "                    Fm[k] += self.learning_rate * self.trees[m][k].predict(x)\n",
    "\n",
    "\n",
    "            den = np.array([0]*len(x)).astype(np.float64)\n",
    "            for l in range(self.num_class):\n",
    "                den += np.exp(Fm[l])\n",
    "\n",
    "            for k in range(self.num_class):\n",
    "\n",
    "                # kth tree\n",
    "                p_km = np.exp(Fm[k]) / den\n",
    "                prob.iloc[:, k] = p_km\n",
    "\n",
    "\n",
    "            \n",
    "            return prob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color  0  1  2\n",
      "0      1  0  1  0\n",
      "1      1  0  1  0\n",
      "2      0  1  0  0\n",
      "3      2  0  0  1\n",
      "4      1  0  1  0\n",
      "5      2  0  0  1\n"
     ]
    }
   ],
   "source": [
    "# Create a sample dataframe\n",
    "data = {\n",
    "        'Color': [1, 1, 0, 2, 1, 2]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform one-hot encoding on the 'Color' column\n",
    "one_hot_encoded = pd.get_dummies(df['Color'])\n",
    "\n",
    "# Add the one-hot encoded columns to the original dataframe\n",
    "df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "\n",
    "# Print the result\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 0])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.array([1,-1,-2,0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>exang</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.292453</td>\n",
       "      <td>0.196347</td>\n",
       "      <td>0.740458</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.175799</td>\n",
       "      <td>0.641221</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.481132</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.412214</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.175799</td>\n",
       "      <td>0.687023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>0.383562</td>\n",
       "      <td>0.267176</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.216895</td>\n",
       "      <td>0.709924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.292453</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.340183</td>\n",
       "      <td>0.358779</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.292237</td>\n",
       "      <td>0.671756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.141553</td>\n",
       "      <td>0.320611</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  trestbps      chol   thalach   oldpeak  sex  cp  fbs  restecg  \\\n",
       "0     0.479167  0.292453  0.196347  0.740458  0.161290    1   0    0        1   \n",
       "1     0.500000  0.433962  0.175799  0.641221  0.500000    1   0    1        0   \n",
       "2     0.854167  0.481132  0.109589  0.412214  0.419355    1   0    0        1   \n",
       "3     0.666667  0.509434  0.175799  0.687023  0.000000    1   0    0        1   \n",
       "4     0.687500  0.415094  0.383562  0.267176  0.306452    0   0    1        1   \n",
       "...        ...       ...       ...       ...       ...  ...  ..  ...      ...   \n",
       "1020  0.625000  0.433962  0.216895  0.709924  0.000000    1   1    0        1   \n",
       "1021  0.645833  0.292453  0.301370  0.534351  0.451613    1   0    0        0   \n",
       "1022  0.375000  0.150943  0.340183  0.358779  0.161290    1   0    0        0   \n",
       "1023  0.437500  0.150943  0.292237  0.671756  0.000000    0   0    0        0   \n",
       "1024  0.520833  0.245283  0.141553  0.320611  0.225806    1   0    0        1   \n",
       "\n",
       "      exang  slope  ca  thal  \n",
       "0         0      2   2     3  \n",
       "1         1      0   0     3  \n",
       "2         1      0   0     3  \n",
       "3         0      2   1     3  \n",
       "4         0      1   3     2  \n",
       "...     ...    ...  ..   ...  \n",
       "1020      1      2   0     2  \n",
       "1021      1      1   1     3  \n",
       "1022      1      1   1     2  \n",
       "1023      0      2   0     2  \n",
       "1024      0      1   1     3  \n",
       "\n",
       "[1025 rows x 13 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heart = pd.read_csv('D:\\\\STATS4T06\\\\Datasets\\\\heartdf.csv')\n",
    "\n",
    "trainx_heart = df_heart.iloc[:,1:14]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "trainx_heart['age'] = scaler.fit_transform(trainx_heart[['age']])\n",
    "trainx_heart['trestbps'] = scaler.fit_transform(trainx_heart[['trestbps']])\n",
    "trainx_heart['chol'] = scaler.fit_transform(trainx_heart[['chol']])\n",
    "trainx_heart['thalach'] = scaler.fit_transform(trainx_heart[['thalach']])\n",
    "trainx_heart['oldpeak'] = scaler.fit_transform(trainx_heart[['oldpeak']])\n",
    "\n",
    "trainy_heart = df_heart.iloc[:,14]\n",
    "\n",
    "\n",
    "trainx_heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = gradient_boosting(M=10,max_depth = 3,method=\"multiclass classification\")\n",
    "gb.fit(trainx_heart.iloc[:,0:4],trainy_heart)\n",
    "\n",
    "# heart_log_loss = logisticloss(trainy_heart,gb.predit(trainx_heart.iloc[:,0:4]))\n",
    "\n",
    "# heart_log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\99506\\AppData\\Local\\Temp\\ipykernel_35324\\4197482316.py:186: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  prob.iloc[:, k] = p_km\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.49341501, 0.49341501, 0.49341501, 0.49341501, 0.49341501,\n",
       "       0.49341501, 0.49341501])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(gb.predit(trainx_heart.iloc[:,0:4]).iloc[:,0])\n",
    "\n",
    "#np.where(gb.predit(trainx_heart.iloc[:,0:4]) > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5921264209375903"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(trainy_heart, np.where(gb.predit(trainx_heart.iloc[:,0:4]) > 0.5, 1, 0))\n",
    "adjusted_rand_score(trainy_heart, np.where(gb.predit(trainx_heart.iloc[:,0:4]) > 0.5, 1, 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ab9e1c345c6ca72aee2a9dc5c191881083c1e0904cd418eb537d62ed6bc1fcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
